{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'feminine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " 'masculine',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/french_clean.txt\") as f:\n",
    "        text = f.readlines()\n",
    "nouns = []\n",
    "labels = []\n",
    "for x in text:\n",
    "        n, l = x.split(\",\")\n",
    "        nouns.append(n)\n",
    "        labels.append(l.strip())\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>noun</th>\n",
       "      <th>gender</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>abandonnataire</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>abélite</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>Abkhaze</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>Ablon</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>abolitioniste</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498124</th>\n",
       "      <td>517171</td>\n",
       "      <td>zythophile</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498125</th>\n",
       "      <td>517172</td>\n",
       "      <td>zythum</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498126</th>\n",
       "      <td>517173</td>\n",
       "      <td>zyzel</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498127</th>\n",
       "      <td>517174</td>\n",
       "      <td>zāy</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498128</th>\n",
       "      <td>517175</td>\n",
       "      <td>Ḫuwawa</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index            noun     gender lang\n",
       "0           85  abandonnataire   feminine   fr\n",
       "1           86         abélite   feminine   fr\n",
       "2           87         Abkhaze   feminine   fr\n",
       "3           88           Ablon   feminine   fr\n",
       "4           89   abolitioniste   feminine   fr\n",
       "...        ...             ...        ...  ...\n",
       "498124  517171      zythophile  masculine   fr\n",
       "498125  517172          zythum  masculine   fr\n",
       "498126  517173           zyzel  masculine   fr\n",
       "498127  517174             zāy  masculine   fr\n",
       "498128  517175          Ḫuwawa  masculine   fr\n",
       "\n",
       "[498129 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/wiktionary_raw.csv\")\n",
    "df = df.dropna().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>gender</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonnataire</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abélite</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abkhaze</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ablon</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abolitioniste</td>\n",
       "      <td>feminine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498124</th>\n",
       "      <td>zythophile</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498125</th>\n",
       "      <td>zythum</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498126</th>\n",
       "      <td>zyzel</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498127</th>\n",
       "      <td>zāy</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498128</th>\n",
       "      <td>Ḫuwawa</td>\n",
       "      <td>masculine</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82532 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  noun     gender lang\n",
       "0       abandonnataire   feminine   fr\n",
       "1              abélite   feminine   fr\n",
       "2              Abkhaze   feminine   fr\n",
       "3                Ablon   feminine   fr\n",
       "4        abolitioniste   feminine   fr\n",
       "...                ...        ...  ...\n",
       "498124      zythophile  masculine   fr\n",
       "498125          zythum  masculine   fr\n",
       "498126           zyzel  masculine   fr\n",
       "498127             zāy  masculine   fr\n",
       "498128          Ḫuwawa  masculine   fr\n",
       "\n",
       "[82532 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_df = df[df['lang'] == 'fr']\n",
    "french_df = french_df.drop(columns=['index'])\n",
    "french_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82532\n",
      "82532\n"
     ]
    }
   ],
   "source": [
    "X = french_df['noun'].to_list()\n",
    "y = french_df['gender'].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NounDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_length):\n",
    "        self.X = X\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.le = LabelEncoder()\n",
    "        self.y = self.le.fit_transform(y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.X[idx]\n",
    "        label = torch.tensor(self.y[idx])\n",
    "\n",
    "        encoded_text = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return  {\n",
    "        'input_ids': encoded_text['input_ids'].squeeze(),\n",
    "        'attention_mask': encoded_text['attention_mask'].squeeze(),\n",
    "        'label': label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(set(y_train)))\n",
    "# Example usage\n",
    "# Assuming you have X_train, y_train, X_test, y_test defined\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Create datasets and loaders\n",
    "max_length = 32  # Adjust based on your preference\n",
    "train_dataset = NounDataset(X_train, y_train, tokenizer, max_length)\n",
    "test_dataset = NounDataset(X_test, y_test, tokenizer, max_length)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderBert(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, epochs, device, model):\n",
    "        super(GenderBert, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tagset_size = tagset_size\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.bert = model.bert\n",
    "\n",
    "        \n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \n",
    "\n",
    "        num_epochs = self.epochs\n",
    "        model.to(self.device)\n",
    "        for epoch in range(num_epochs):\n",
    "            # model.train()\n",
    "            for batch in train_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['label'].squeeze().long().to(self.device)  # Ensure labels are of type long\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
    "        \n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        # Evaluation\n",
    "        # model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does not exist\n"
     ]
    }
   ],
   "source": [
    "# Set your desired values for these parameters\n",
    "embedding_dim = 768  # Adjust based on your model architecture\n",
    "hidden_dim = 256  # Adjust based on your model architecture\n",
    "vocab_size = 32000  # Adjust based on your dataset vocabulary size\n",
    "tagset_size = 2  # Assuming binary classification (e.g., male/female)\n",
    "epochs = 5  # Adjust based on your training preferences\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available\n",
    "\n",
    "folder_path = 'saved_models'\n",
    "file_name = 'GenderBert_params.pth'\n",
    "\n",
    "file_path = Path(folder_path) / file_name\n",
    "\n",
    "\n",
    "    # Initialize model\n",
    "if file_path.exists():\n",
    "    gender_clf = GenderBert(\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        vocab_size=vocab_size,\n",
    "        tagset_size=tagset_size,\n",
    "        epochs=epochs,\n",
    "        model=model,\n",
    "        device=device\n",
    "        )\n",
    "\n",
    "    gender_clf.load_state_dict(torch.load(file_path))\n",
    "    print(f\"Model loaded successfully from {file_path}.\")\n",
    "    result = gender_clf.predict(test_loader)\n",
    "else:\n",
    "    print('does not exist')\n",
    "    gender_clf = GenderBert(embedding_dim, hidden_dim, vocab_size, tagset_size, epochs, device, model)\n",
    "    torch.save(gender_clf.state_dict(), 'saved_models/GenderBert_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.20045024156570435\n",
      "Epoch 2/5, Loss: 0.2990168333053589\n",
      "Epoch 3/5, Loss: 0.1385294646024704\n",
      "Epoch 4/5, Loss: 0.061162617057561874\n",
      "Epoch 5/5, Loss: 0.05526687949895859\n"
     ]
    }
   ],
   "source": [
    "gender_clf.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.24%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8624048853777928"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_clf.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ['cat']\n",
    "src_langs = \"-\".join([lang for lang in args])\n",
    "src_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "class GenderBert2(nn.Module):\n",
    "    def __init__(self, num_labels=None):\n",
    "        super(GenderBert2, self).__init__()\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "    def train_model(self, train_loader, device, num_epochs=3):\n",
    "        self.model.to(device)  # Move model to the desired device\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in train_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].squeeze().long().to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    def evaluate(self, data_loader, device, mode='test'):\n",
    "        self.model.to(device)  # Move model to the desired device\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'{mode.capitalize()} Accuracy: {accuracy * 100:.2f}%')\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Loss: 0.5338936448097229\n",
      "Epoch 2/6, Loss: 0.18931609392166138\n",
      "Epoch 3/6, Loss: 0.14981752634048462\n",
      "Epoch 4/6, Loss: 0.09604091942310333\n",
      "Epoch 5/6, Loss: 0.03908614441752434\n",
      "Epoch 6/6, Loss: 0.47648361325263977\n"
     ]
    }
   ],
   "source": [
    "clf = GenderBert2(len(y_train))\n",
    "clf.train_model(train_loader, device='cuda', num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.21%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.862114089080599"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': clf.model.state_dict(),\n",
    "    'tokenizer': clf.tokenizer\n",
    "}, '../saved_models/bert_fr_to_fr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
